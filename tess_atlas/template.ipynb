{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESS Atlas fit for TOI {{{TOINUMBER}}}\n",
    "\n",
    "**Version: {{{VERSIONNUMBER}}}**\n",
    "\n",
    "**Note: This notebook was automatically generated as part of the TESS Atlas project. More information can be found on GitHub:** [github.com/dfm/tess-atlas](https://github.com/dfm/tess-atlas)\n",
    "\n",
    "In this notebook, we do a quicklook fit for the parameters of the TESS Objects of Interest (TOI) in the system number {{{TOINUMBER}}}.\n",
    "To do this fit, we use the [exoplanet](https://exoplanet.dfm.io) library and you can find more information about that project at [exoplanet.dfm.io](https://exoplanet.dfm.io).\n",
    "\n",
    "From here, you can scroll down and take a look at the fit results, or you can:\n",
    "\n",
    "- [open the notebook in Google Colab to run the fit yourself](https://colab.research.google.com/github/dfm/tess-atlas/blob/gh-pages/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb),\n",
    "- [view the notebook on GitHub](https://github.com/dfm/tess-atlas/blob/gh-pages/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb), or\n",
    "- [download the notebook](https://github.com/dfm/tess-atlas/raw/gh-pages/notebooks/{{{VERSIONNUMBER}}}/toi-{{{TOINUMBER}}}.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "## Caveats\n",
    "\n",
    "There are many caveats associated with this relatively simple \"quicklook\" type of analysis that should be kept in mind.\n",
    "Here are some of the main things that come to mind:\n",
    "\n",
    "1. The orbits that we fit are constrained to be *circular*. One major effect of this approximation is that the fit will significantly overestimate the confidence of the impact parameter constraint, so the results for impact parameter shouldn't be taken too seriously. \n",
    "\n",
    "2. Transit timing variations, correlated noise, and (probably) your favorite systematics are ignored. Sorry!\n",
    "\n",
    "3. This notebook was generated automatically without human intervention. Use at your own risk!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Getting started](#Getting-started)\n",
    "2. [Data & de-trending](#Data-%26amp%3B-de-trending)\n",
    "3. [Removing stellar variability](#Removing-stellar-variability)\n",
    "4. [Transit model in PyMC3 & exoplanet](#Transit-model-in-PyMC3-%26amp%3B-exoplanet)\n",
    "5. [Sampling](#Sampling)\n",
    "6. [Posterior constraints](#Posterior-constraints)\n",
    "7. [Attribution](#Attribution)\n",
    "\n",
    "## Getting started\n",
    "\n",
    "To get going, we'll need to make out plots show up inline and install a few packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "!pip install -q -U lightkurve fbpca exoplanet corner pymc3 dynesty isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll set up the plotting styles and do all of the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "import exoplanet as xo\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import corner\n",
    "import astropy.units as u\n",
    "from astroquery.mast import Catalogs\n",
    "import pandas as pd\n",
    "import functools\n",
    "\n",
    "get_ipython().magic('config InlineBackend.figure_format = \"retina\"')\n",
    "\n",
    "# TEMPORARY WORKAROUND\n",
    "mp.set_start_method(\"fork\")\n",
    "\n",
    "# Don't use the schmantzy progress bar\n",
    "os.environ[\"EXOPLANET_NO_AUTO_PBAR\"] = \"true\"\n",
    "\n",
    "# Warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Logging setup\n",
    "logger = logging.getLogger(\"theano.gof.compilelock\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "logger = logging.getLogger(\"exoplanet\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# matplotlib settings\n",
    "plt.style.use(\"default\")\n",
    "plt.rcParams[\"savefig.dpi\"] = 100\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Liberation Sans\"]\n",
    "plt.rcParams[\"font.cursive\"] = [\"Liberation Sans\"]\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"custom\"\n",
    "\n",
    "# Constants\n",
    "TOI_DATASOURCE = \"https://exofop.ipac.caltech.edu/tess/download_toi.php?sort=toi&output=csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "TOI_NUMBER = {{{TOINUMBER}}}\n",
    "__version__ = {{{VERSIONNUMBER}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting stellar parameters\n",
    "\n",
    "Next, we grab the TOI list from [ExoFOP](https://exofop.ipac.caltech.edu/tess/) to get the information about the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def get_toi_data_from_database(toi_number):\n",
    "    # Get the table of TOI info from ExoFOP\n",
    "    tois = pd.read_csv(TOI_DATASOURCE)\n",
    "\n",
    "    # Select all of the rows in the TOI table that are associated with this target\n",
    "    toi = tois[tois[\"TOI\"] == toi_number + 0.01].iloc[0]\n",
    "    tic = toi['TIC ID']\n",
    "    tois = tois[tois[\"TIC ID\"] == tic].sort_values(\"TOI\")\n",
    "    return tois\n",
    "\n",
    "\n",
    "\n",
    "class TOI:\n",
    "    \"\"\"TOI object to hold information about tois\"\"\"\n",
    "    def __init__(self, toi_number):\n",
    "        self.toi_number = toi_number\n",
    "\n",
    "    @property\n",
    "    def toi_number(self):\n",
    "        return self.__toi_number\n",
    "\n",
    "    @toi_number.setter\n",
    "    def toi_number(self, value):\n",
    "        self.__toi_number = value\n",
    "        self.__toi_data = get_toi_data_from_database(value)\n",
    "\n",
    "    @property\n",
    "    def tic(self):\n",
    "        return self.__toi_data['TIC ID'].iloc[0]\n",
    "\n",
    "    @property\n",
    "    def periods(self):\n",
    "        \"\"\"Planet periods\"\"\"\n",
    "        periods = np.array(self.__toi_data[\"Period (days)\"], dtype=float)\n",
    "        assert np.all(periods > 0), \"We haven't implemented single transits yet\"\n",
    "        return periods\n",
    "\n",
    "    @property\n",
    "    def t0s(self):\n",
    "        \"\"\"Phase (converted from BJD to TBJD)\"\"\"\n",
    "        return np.array(self.__toi_data[\"Epoch (BJD)\"], dtype=float) - 2457000\n",
    "\n",
    "    @property\n",
    "    def depths(self):\n",
    "        \"\"\"Depth to parts per thousand (from parts per million)\"\"\"\n",
    "        return 1e-3 * np.array(self.__toi_data[\"Depth (ppm)\"], dtype=float)\n",
    "\n",
    "    @property\n",
    "    def duration(self):\n",
    "        \"\"\"Duration in days (from hours)\"\"\"\n",
    "        return np.array(tois[\"Duration (hours)\"], dtype=float) / 24.0\n",
    "\n",
    "    @property\n",
    "    def letters(self):\n",
    "        \"\"\"Letters to identify each candidate\"\"\"\n",
    "        return \"bcdefghijklmnopqrstuvwxyz\"[:len(self.periods)]\n",
    "\n",
    "    def setup_outdir(self, version):\n",
    "        output_dir = os.path.join(\"results\", version, f\"{self.toi_number}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.outdir = output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "toi = TOI(toi_number=TOI_NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, let's download the TESS light curve using [lightkurve](https://docs.lightkurve.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "class TicLightcurve:\n",
    "    \"\"\"Object to hold lightcurve information of a Tic\"\"\"\n",
    "    def __init__(self, tic):\n",
    "        \"\"\"\n",
    "        Sets up a lightcurve object given the tic, with attributes\n",
    "        time [days]\n",
    "        flux [the relative flux in ppt]\n",
    "\n",
    "        Args:\n",
    "            tic: int, tic id of a TOI\n",
    "        \"\"\"\n",
    "        self.tic = tic\n",
    "        self.__lc = self.get_lightcurve()\n",
    "        self.time = np.ascontiguousarray(self.__lc.time, dtype=np.float64)\n",
    "        self.flux = np.ascontiguousarray(1e3 * (self.__lc.flux - 1), dtype=np.float64)\n",
    "        self.flux_err = np.ascontiguousarray(1e3 * self.__lc.flux_err, dtype=np.float64)\n",
    "\n",
    "    def get_lightcurve(self):\n",
    "        lcfs = lk.search_lightcurvefile(\n",
    "            f\"TIC {self.tic}\",\n",
    "            mission=\"TESS\"\n",
    "        ).download_all()\n",
    "        lc = lcfs.PDCSAP_FLUX.stitch()\n",
    "        lc = lc.remove_nans().remove_outliers()\n",
    "        return lc\n",
    "\n",
    "    @property\n",
    "    @functools.lru_cache()\n",
    "    def period(self):\n",
    "        \"\"\"period of a time series using box least squares\"\"\"\n",
    "        return xo.estimators.bls_estimator(\n",
    "            self.time,\n",
    "            self.flux,\n",
    "            self.flux_err,\n",
    "            min_period=2,\n",
    "            max_period=20\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def period_guess(self):\n",
    "        return self.period[\"peak_info\"][\"period\"]\n",
    "\n",
    "    @property\n",
    "    def t0_guess(self):\n",
    "        return self.period[\"peak_info\"][\"transit_time\"]\n",
    "\n",
    "    @property\n",
    "    def depth_guess(self):\n",
    "        return self.period[\"peak_info\"][\"depth\"]\n",
    "\n",
    "    def mask_lightcurve(self, days:float):\n",
    "        \"\"\"Mask lightcurce data to look only at the central \"days\" duration of data \"\"\"\n",
    "        transit_mask = (\n",
    "            np.abs((self.time - self.t0_guess + 0.5 * self.period_guess) % self.period_guess - 0.5 * self.period_guess)\n",
    "            < days\n",
    "        )\n",
    "        self.time = np.ascontiguousarray(self.time[transit_mask])\n",
    "        self.flux = np.ascontiguousarray(self.flux[transit_mask])\n",
    "        self.flux_err = np.ascontiguousarray(self.flux_err[transit_mask])\n",
    "\n",
    "\n",
    "\n",
    "def plot_lightcurve(lc:TicLightcurve):\n",
    "    plt.plot(lc.time, lc.flux, \"k\", linewidth=0.5)\n",
    "    plt.xlabel(\"time [days]\")\n",
    "    plt.ylabel(\"relative flux [ppt]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "lc = TicLightcurve(tic=toi.tic)\n",
    "plot_lightcurve(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, find the period, phase and depth of the transit using box least squares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_lightcurve_power_vs_period(lc:TicLightcurve):\n",
    "    plt.plot(lc.period[\"bls\"].period, lc.period[\"bls\"].power, \"k\", linewidth=0.5)\n",
    "    plt.axvline(lc.period_guess, alpha=0.3, linewidth=5)\n",
    "    plt.xlabel(\"period [days]\")\n",
    "    plt.ylabel(\"bls power\")\n",
    "    plt.yticks([])\n",
    "    plt.xlim(lc.period[\"bls\"].period.min(), lc.period[\"bls\"].period.max());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_lightcurve_power_vs_period(lc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for efficiency purposes, let's extract just the data within 0.25 days of the transits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_masked_lightcurve_flux_vs_time_since_transit(lc:TicLightcurve, days:float):\n",
    "    time_fold = (lc.time - lc.t0_guess + 0.5 * lc.period_guess) % lc.period_guess - 0.5 * lc.period_guess\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.scatter(time_fold, lc.flux, c=lc.time, s=3)\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"relative flux [ppt]\")\n",
    "    plt.colorbar(label=\"time [days]\")\n",
    "    plt.xlim(-days, days);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "days = 0.25\n",
    "lc.mask_lightcurve(days)\n",
    "plot_masked_lightcurve_flux_vs_time_since_transit(lc, days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "That looks a little janky, but it's good enough for now.\n",
    "\n",
    "## The probabilistic model\n",
    "\n",
    "Here's how we set up the PyMC3 model in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    with pm.Model() as toi_model:\n",
    "        # Stellar parameters\n",
    "        mean = pm.Normal(\"mean\", mu=0.0, sigma=10.0)\n",
    "        u = xo.distributions.QuadLimbDark(\"u\")\n",
    "        star_params = [mean, u]\n",
    "\n",
    "        # Gaussian process noise model priors\n",
    "        sigma = pm.InverseGamma(\"sigma\", alpha=3.0, beta=2 * np.median(lc.flux_err))\n",
    "        log_Sw4 = pm.Normal(\"log_Sw4\", mu=0.0, sigma=10.0)\n",
    "        log_w0 = pm.Normal(\"log_w0\", mu=np.log(2 * np.pi / 10.0), sigma=10.0)\n",
    "        kernel = xo.gp.terms.SHOTerm(log_Sw4=log_Sw4, log_w0=log_w0, Q=1.0 / 3)\n",
    "        noise_params = [sigma, log_Sw4, log_w0]\n",
    "\n",
    "        # Planet parameters priors\n",
    "        log_ror = pm.Normal(\"log_ror\", mu=0.5 * np.log(lc.depth_guess * 1e-3), sigma=10.0)\n",
    "        ror = pm.Deterministic(\"ror\", tt.exp(log_ror))\n",
    "\n",
    "        # Orbital parameters priors\n",
    "        log_period = pm.Normal(\"log_period\", mu=np.log(lc.period_guess), sigma=1.0)\n",
    "        t0 = pm.Normal(\"t0\", mu=lc.t0_guess, sigma=1.0)\n",
    "        log_dur = pm.Normal(\"log_dur\", mu=np.log(0.1), sigma=10.0)\n",
    "        b = xo.distributions.ImpactParameter(\"b\", ror=ror)\n",
    "\n",
    "        period = pm.Deterministic(\"period\", tt.exp(log_period))\n",
    "        dur = pm.Deterministic(\"dur\", tt.exp(log_dur))\n",
    "\n",
    "        # Set up the orbit\n",
    "        orbit = xo.orbits.KeplerianOrbit(period=period, duration=dur, t0=t0, b=b)\n",
    "\n",
    "        # We're going to track the implied density for reasons that will become clear later\n",
    "        pm.Deterministic(\"rho_circ\", orbit.rho_star) # rho circ is part of the model\n",
    "\n",
    "        # Set up the mean transit model\n",
    "        star = xo.LimbDarkLightCurve(u)\n",
    "\n",
    "        def lc_model(t):\n",
    "            return mean + 1e3 * tt.sum(\n",
    "                star.get_light_curve(orbit=orbit, r=ror, t=t), axis=-1\n",
    "            )\n",
    "\n",
    "        # Finally the GP observation model\n",
    "        gp = xo.gp.GP(kernel, lc.time, lc.flux_err ** 2 + sigma ** 2, mean=lc_model)\n",
    "        gp.marginal(\"obs\", observed=lc.flux) # compute likelihood (observed == data)\n",
    "\n",
    "        # Double check that everything looks good - we shouldn't see any NaNs!\n",
    "        print(toi_model.check_test_point())\n",
    "        \n",
    "        # cache params \n",
    "        params = dict(\n",
    "            sigma=sigma,\n",
    "            log_ror=log_ror,\n",
    "            b=b,\n",
    "            log_dur=log_dur,\n",
    "            noise_params = noise_params,\n",
    "            star_params=star_params\n",
    "        )\n",
    "\n",
    "        return toi_model, params, lc_model, gp\n",
    "            \n",
    "            \n",
    "def optimize_model(model, sigma, log_ror, b, log_dur, noise_params, star_params):\n",
    "    with model:         \n",
    "        map_soln = model.test_point\n",
    "        map_soln = xo.optimize(map_soln, [sigma])\n",
    "        map_soln = xo.optimize(map_soln, [log_ror, b, log_dur])\n",
    "        map_soln = xo.optimize(map_soln, noise_params)\n",
    "        map_soln = xo.optimize(map_soln, star_params)\n",
    "        map_soln = xo.optimize(map_soln)\n",
    "        return map_soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "toi_model, params, lc_model, gp = build_model()\n",
    "map_soln = optimize_model(toi_model, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can plot our initial model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_model(lc, toi_model, map_soln):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    time_fold = (lc.time - map_soln[\"t0\"] + 0.5 * map_soln[\"period\"]) % map_soln[\n",
    "        \"period\"\n",
    "    ] - 0.5 * map_soln[\"period\"]\n",
    "    inds = np.argsort(time_fold)\n",
    "    plt.scatter(time_fold, lc.flux - gp_pred - map_soln[\"mean\"], c=lc.time, s=3)\n",
    "    plt.plot(time_fold[inds], lc_pred[inds] - map_soln[\"mean\"], \"k\")\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"relative flux [ppt]\")\n",
    "    plt.colorbar(label=\"time [days]\")\n",
    "    plt.xlim(-days, days);\n",
    "    \n",
    "    \n",
    "def obtain_prediction(model, gp, lc_model, map_soln):\n",
    "    with model:\n",
    "        gp_pred, lc_pred = xo.eval_in_model([gp.predict(), lc_model(lc.time)], map_soln)\n",
    "        return gp_pred, lc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_model(lc, toi_model, map_soln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "That looks better!\n",
    "\n",
    "Now on to sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "TUNE = 10\n",
    "DRAWS = 10\n",
    "CHAINS = 1\n",
    "\n",
    "np.random.seed(286923464)\n",
    "\n",
    "def start_model_sampling(model):\n",
    "    with model:\n",
    "        trace = pm.sample(\n",
    "            tune=TUNE,\n",
    "            draws=DRAWS,\n",
    "            start=map_soln,\n",
    "            chains=CHAINS,\n",
    "            cores=1,\n",
    "            step=xo.get_dense_nuts_step(target_accept=0.9)\n",
    "        )\n",
    "        return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "trace = start_model_sampling(toi_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we can take a look at the summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And plot the posterior covariances compared to the values from [Pepper et al. (2019)](https://arxiv.org/abs/1911.05150):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_posteriors(trace):\n",
    "    samples = pm.trace_to_dataframe(trace, varnames=[\"period\", \"ror\", \"b\"])\n",
    "    corner.corner(samples);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_posteriors(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bonus: eccentricity\n",
    "\n",
    "As discussed above, we fit this model assuming a circular orbit which speeds things up for a few reasons.\n",
    "First, setting eccentricity to zero means that the orbital dynamics are much simpler and more computationally efficient, since we don't need to solve Kepler's equation numerically.\n",
    "But this isn't actually the main effect!\n",
    "Instead the bigger issues come from the fact that the degeneracies between eccentricity, arrgument of periasteron, impact parameter, and planet radius are hard for the sampler to handle, causing the sampler's performance to plummet.\n",
    "In this case, by fitting with a circular orbit where duration is one of the parameters, everything is well behaved and the sampler runs faster.\n",
    "\n",
    "But, in this case, the planet *is* actually on an eccentric orbit, so that assumption isn't justified.\n",
    "It has been recognized by various researchers over the years (I first learned about this from [Bekki Dawson](https://arxiv.org/abs/1203.5537)) that, to first order, the eccentricity mainly just changes the transit duration.\n",
    "The key realization is that this can be thought of as a change in the impled density of the star.\n",
    "Therefore, if you fit the transit using stellar density (or duration, in this case) as one of the parameters (*note: you must have a* different *stellar density parameter for each planet if there are more than one*), you can use an independent measurement of the stellar density to infer the eccentricity of the orbit after the fact.\n",
    "All the details are described in [Dawson & Johnson (2012)](https://arxiv.org/abs/1203.5537), but here's how you can do this here using the stellar density listed in the TESS input catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "def"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_reweighted_ecentricity_samples(toi, trace):\n",
    "    star = Catalogs.query_object(f\"TIC {toi.tic}\", catalog=\"TIC\", radius=0.001)\n",
    "    tic_rho_star = float(star[\"rho\"]), float(star[\"e_rho\"])\n",
    "    print(\"rho_star = {0} ± {1}\".format(*tic_rho_star))\n",
    "\n",
    "    # Extract the implied density from the fit\n",
    "    rho_circ = np.repeat(trace[\"rho_circ\"], 100)\n",
    "\n",
    "    # Sample eccentricity and omega from their priors (the math might\n",
    "    # be a little more subtle for more informative priors, but I leave\n",
    "    # that as an exercise for the reader...)\n",
    "    ecc = np.random.uniform(0, 1, len(rho_circ))\n",
    "    omega = np.random.uniform(-np.pi, np.pi, len(rho_circ))\n",
    "\n",
    "    # Compute the \"g\" parameter from Dawson & Johnson and what true\n",
    "    # density that implies\n",
    "    g = (1 + ecc * np.sin(omega)) / np.sqrt(1 - ecc ** 2)\n",
    "    rho = rho_circ / g ** 3\n",
    "\n",
    "    # Re-weight these samples to get weighted posterior samples\n",
    "    log_weights = -0.5 * ((rho - tic_rho_star[0]) / tic_rho_star[1]) ** 2\n",
    "    weights = np.exp(log_weights - np.max(log_weights))\n",
    "\n",
    "    # Estimate the expected posterior quantiles\n",
    "    q = corner.quantile(ecc, [0.16, 0.5, 0.84], weights=weights)\n",
    "    print(\"eccentricity = {0:.2f} +{1[1]:.2f} -{1[0]:.2f}\".format(q[1], np.diff(q)))\n",
    "\n",
    "    corner.corner(\n",
    "        np.vstack((ecc, omega)).T,\n",
    "        weights=weights,\n",
    "        plot_datapoints=False,\n",
    "        labels=[\"eccentricity\", \"omega\"],\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "plot_reweighted_ecentricity_samples(toi, trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As you can see, this eccentricity estimate is consistent (albeit with large uncertainties) with the value that [Pepper et al. (2019)](https://arxiv.org/abs/1911.05150) measure using radial velocities and it is definitely clear that this planet is not on a circular orbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "As described in the :ref:`citation` tutorial, we can use :func:`exoplanet.citations.get_citations_for_model` to construct an acknowledgement and BibTeX listing that includes the relevant citations for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "with toi_model:\n",
    "    txt, bib = xo.citations.get_citations_for_model()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "exe"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join(bib.splitlines()[:10]) + \"\\n...\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}