{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESS Atlas fit for TOI 144\n",
    "\n",
    "**Version: 0.1.0**\n",
    "\n",
    "**Note: This notebook was automatically generated as part of the TESS Atlas project. More information can be found on GitHub:** [github.com/dfm/tess-atlas](https://github.com/dfm/tess-atlas)\n",
    "\n",
    "In this notebook, we do a quicklook fit for the parameters of the TESS Objects of Interest (TOI) in the system number 144.\n",
    "To do this fit, we use the [exoplanet](https://exoplanet.dfm.io) library and you can find more information about that project at [exoplanet.dfm.io](https://exoplanet.dfm.io).\n",
    "\n",
    "From here, you can scroll down and take a look at the fit results, or you can:\n",
    "\n",
    "- [open the notebook in Google Colab to run the fit yourself](https://colab.research.google.com/github/dfm/tess-atlas/blob/master/notebooks/0.1.0/toi-144.ipynb),\n",
    "- [view the notebook on GitHub](https://github.com/dfm/tess-atlas/blob/master/notebooks/0.1.0/toi-144.ipynb), or\n",
    "- [download the notebook](https://github.com/dfm/tess-atlas/raw/master/notebooks/0.1.0/toi-144.ipynb).\n",
    "\n",
    "## Caveats\n",
    "\n",
    "There are many caveats associated with this relatively simple \"quicklook\" type of analysis that should be kept in mind.\n",
    "Here are some of the main things that come to mind:\n",
    "\n",
    "1. The orbits that we fit are constrained to be *circular*. One major effect of this approximation is that the fit will significantly overestimate the confidence of the impact parameter constraint, so the results for impact parameter shouldn't be taken too seriously. \n",
    "\n",
    "2. Others TBD\n",
    "\n",
    "## Getting started\n",
    "\n",
    "To get going, we'll need to make out plots show up inline and install a few packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "!pip install -q -U lightkurve fbpca exoplanet corner pymc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll set up the plotting styles and do all of the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 16\n",
    "rcParams[\"text.usetex\"] = False\n",
    "rcParams[\"font.family\"] = [\"sans-serif\"]\n",
    "rcParams[\"font.sans-serif\"] = [\"cmss10\"]\n",
    "rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import corner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pymc3 as pm\n",
    "import exoplanet as xo\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & de-trending\n",
    "\n",
    "Next, we grab the TOI list from [ExoFOP](https://exofop.ipac.caltech.edu/tess/) to get the information about the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toi_num = 144\n",
    "\n",
    "# Get the table of TOI info from ExoFOP\n",
    "tois = pd.read_csv(\"https://exofop.ipac.caltech.edu/tess/download_toi.php?sort=toi&output=csv\")\n",
    "\n",
    "# Select all of the rows in the TOI table that are associated with this target\n",
    "toi = tois[tois[\"TOI\"] == toi_num + 0.01].iloc[0]\n",
    "tic = toi['TIC ID']\n",
    "tois = tois[tois[\"TIC ID\"] == tic].sort_values(\"TOI\")\n",
    "\n",
    "# Extract the planet periods\n",
    "periods = np.array(tois[\"Period (days)\"], dtype=float)\n",
    "\n",
    "# Convert the phase to TBJD from BJD\n",
    "t0s = np.array(tois[\"Epoch (BJD)\"], dtype=float) - 2457000\n",
    "\n",
    "# Convert the depth to parts per thousand from parts per million\n",
    "depths = 1e-3 * np.array(tois[\"Depth (ppm)\"], dtype=float)\n",
    "\n",
    "# Convert the duration to days from hours\n",
    "durations = np.array(tois[\"Duration (hours)\"], dtype=float) / 24.0\n",
    "\n",
    "# Extract the stellar radius from the table\n",
    "toi_r_star = toi['Stellar Radius (R_Sun)']\n",
    "toi_r_star_err = toi['Stellar Radius (R_Sun) err']\n",
    "has_r_star = True\n",
    "\n",
    "# If there is no entry in the table (does this ever happen?)\n",
    "if not (np.isfinite(toi_r_star) and np.isfinite(toi_r_star_err)):\n",
    "    toi_r_star = 1.0\n",
    "    toi_r_star_err = 0.0\n",
    "    has_r_star = False\n",
    "\n",
    "# These are the letters that will be used to identify each candidate\n",
    "# (are we being a bit optimistic?)\n",
    "letters = \"bcdefghijklmnopqrstuvwxyz\"[:len(periods)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the [lightkurve](https://docs.lightkurve.org) library to download and de-trend the time series using [pixel-level decorrelation (PLD)](https://docs.lightkurve.org/api/lightkurve.correctors.PLDCorrector.html).\n",
    "We read in target pixel files (TPFs) for each of the campaigns in which TOI 144 was observed.\n",
    "To remove systematic noise, we mask out known transits and perform second order PLD. The noise-corrected light curves are stitched together to create a single contiguous light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the target pixel files\n",
    "sr = lk.search_targetpixelfile('TIC %i' % tic)\n",
    "tpf_collection = sr.download_all()\n",
    "\n",
    "# Extract the exposure time associated with the TPF\n",
    "hdr = tpf_collection[0].hdu[1].header\n",
    "texp = hdr[\"FRAMETIM\"] * hdr[\"NUM_FRM\"]\n",
    "texp /= 60.0 * 60.0 * 24.0\n",
    "\n",
    "# This function can be used to estimate which data points are in transit\n",
    "# for known phase, period, and duration\n",
    "def get_transit_mask(t, t0, period, duration):\n",
    "    hp = 0.5*period\n",
    "    return np.abs((t-t0+hp) % period - hp) < 0.5*duration\n",
    "\n",
    "# Run PLD on each TPF to extract the light curves\n",
    "lc_collection = []\n",
    "for tpf in tpf_collection:\n",
    "    mask = np.zeros_like(tpf.time, dtype=bool)\n",
    "    for i in range(len(periods)):\n",
    "        mask |= get_transit_mask(tpf.time, t0s[i], periods[i], 5*durations[i])\n",
    "    pld = tpf.to_corrector(\"pld\")\n",
    "    lc = pld.correct(aperture_mask=\"pipeline\", cadence_mask=~mask, use_gp=False, pld_order=2)\n",
    "    lc_collection.append(lc.normalize())\n",
    "\n",
    "# Normalize and stitch the sectors\n",
    "lc = lc_collection[0]\n",
    "if len(lc_collection) > 1:\n",
    "    lc = lc.append([next_lc for next_lc in lc_collection[1:]])\n",
    "lc = lc.remove_outliers()\n",
    "    \n",
    "lc.scatter();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stellar variability\n",
    "\n",
    "Next up, we remove stellar variability using a Gaussian Processes model fit to the out of transit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data and convert to parts per thousand\n",
    "x = np.ascontiguousarray(lc.time, dtype=np.float64)\n",
    "y = np.ascontiguousarray((lc.flux - 1.0) * 1e3, dtype=np.float64)\n",
    "yerr = np.ascontiguousarray(lc.flux_err * 1e3, dtype=np.float64)\n",
    "\n",
    "# Compute the transit mask\n",
    "mask = np.zeros_like(x, dtype=bool)\n",
    "for i in range(len(periods)):\n",
    "    mask |= get_transit_mask(x, t0s[i], periods[i], 5*durations[i])\n",
    "\n",
    "# Temporarily increase the in transit error bars substantially\n",
    "diag = np.array(yerr**2)\n",
    "diag[mask] *= 1000.0\n",
    "\n",
    "# Build a GP model\n",
    "with pm.Model() as model:\n",
    "    logs2 = pm.Normal(\"logs2\", mu=np.log(1e-4*np.var(y)), sd=10)\n",
    "    logsigma = pm.Normal(\"logsigma\", mu=np.log(np.std(y)), sd=10)\n",
    "    logrho = pm.Normal(\"logrho\", mu=np.log(10.0), sd=10.0)\n",
    "    \n",
    "    kernel = xo.gp.terms.Matern32Term(log_sigma=logsigma, log_rho=logrho)\n",
    "    gp = xo.gp.GP(kernel, x, diag + tt.exp(logs2), J=2)\n",
    "    pm.Potential(\"loglike\", gp.log_likelihood(y))\n",
    "    \n",
    "    map_soln = xo.optimize()\n",
    "    pred = xo.utils.eval_in_model(gp.predict(), map_soln)\n",
    "\n",
    "# Flatten the light curve\n",
    "y -= pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit model in PyMC3 & exoplanet\n",
    "\n",
    "Some more info about the modeling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x, y, yerr, periods, t0s, depths, mask=None, start=None):\n",
    "    \"\"\"Build an exoplanet model for a dataset and set of planets\n",
    "    \n",
    "    Args:\n",
    "        x: The time series (in days); this should probably be centered\n",
    "        y: The relative fluxes (in parts per thousand)\n",
    "        yerr: The uncertainties on ``y``\n",
    "        periods: The periods of the planets (in days)\n",
    "        t0s: The phases of the planets in the same coordinates as ``x``\n",
    "        depths: The depths of the transits in parts per thousand\n",
    "        mask: A boolean mask with the same shape as ``x`` indicating which\n",
    "            data points should be included in the fit\n",
    "        start: A dictionary of model parameters where the optimization\n",
    "            should be initialized\n",
    "            \n",
    "    Returns:\n",
    "        A PyMC3 model specifying the probabilistic model for the light curve\n",
    "\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = np.ones(len(x), dtype=bool)\n",
    "    \n",
    "    periods = np.atleast_1d(periods)\n",
    "    t0s = np.atleast_1d(t0s)\n",
    "    depths = np.atleast_1d(depths)\n",
    "    n_planets = len(periods)\n",
    "    \n",
    "    with pm.Model() as model:\n",
    "        \n",
    "        # Extract the un-masked data points\n",
    "        model.x = x[mask]\n",
    "        model.y = y[mask]\n",
    "        model.yerr = (yerr + np.zeros_like(x))[mask]\n",
    "        model.mask = mask\n",
    "\n",
    "        # The baseline (out-of-transit) flux for the star in ppt. This\n",
    "        # should be close to one because of how we normalized the data\n",
    "        mean = pm.Normal(\"mean\", mu=0.0, sd=10.0)\n",
    "\n",
    "        # The time of a reference transit for each planet\n",
    "        t0 = pm.Normal(\"t0\", mu=t0s, sd=1.0, shape=n_planets)\n",
    "\n",
    "        # The log period; also tracking the period itself\n",
    "        logP = pm.Normal(\"logP\", mu=np.log(periods), sd=0.1, shape=n_planets)\n",
    "        period = pm.Deterministic(\"period\", tt.exp(logP))\n",
    "\n",
    "        # The Kipping (2013) parameterization for quadratic limb darkening paramters\n",
    "        u = xo.distributions.QuadLimbDark(\"u\")\n",
    "\n",
    "        # The Espinoza (2018) parameterization for the joint radius ratio and\n",
    "        # impact parameter distribution\n",
    "        r, b = xo.distributions.get_joint_radius_impact(\n",
    "            min_radius=0.001, max_radius=1.0,\n",
    "            testval_r=np.sqrt(1e-3*np.array(depths)),\n",
    "            testval_b=0.5+np.zeros(n_planets)\n",
    "        )\n",
    "\n",
    "        # This shouldn't make a huge difference, but I like to put a uniform\n",
    "        # prior on the *log* of the radius ratio instead of the value. This\n",
    "        # can be implemented by adding a custom \"potential\" (log probability).\n",
    "        pm.Potential(\"r_prior\", -pm.math.log(r))\n",
    "\n",
    "        # Set up a Keplerian orbit for the planets\n",
    "        model.orbit = xo.orbits.KeplerianOrbit(\n",
    "            period=period, t0=t0, b=b)\n",
    "        \n",
    "        # Compute the model light curve using starry\n",
    "        model.light_curves = xo.StarryLightCurve(u).get_light_curve(\n",
    "            orbit=model.orbit, r=r, t=model.x)\n",
    "        model.light_curve = pm.math.sum(model.light_curves, axis=-1) * 1e3 + mean\n",
    "\n",
    "        # Jitter and likelihood function\n",
    "        logs2 = pm.Normal(\"logs2\", mu=np.log(np.mean(model.yerr)), sd=10)\n",
    "        pm.Normal(\"obs\", mu=model.light_curve, sd=tt.sqrt(model.yerr**2+tt.exp(logs2)),\n",
    "                  observed=model.y)\n",
    "\n",
    "        # Fit for the maximum a posteriori parameters, I've found that I can get\n",
    "        # a better solution by trying different combinations of parameters in turn\n",
    "        if start is None:\n",
    "            start = model.test_point\n",
    "        map_soln = start        \n",
    "        map_soln = xo.optimize(start=map_soln, vars=[logs2, mean])\n",
    "        map_soln = xo.optimize(start=map_soln, vars=[model.rb, mean])\n",
    "        map_soln = xo.optimize(start=map_soln, vars=[logP, t0, mean])\n",
    "        map_soln = xo.optimize(start=map_soln, vars=[model.rb, mean])\n",
    "        map_soln = xo.optimize(start=map_soln)\n",
    "        model.map_soln = map_soln\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and fit for map model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(x, y, yerr, periods, t0s, depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    mean = model.map_soln[\"mean\"]\n",
    "    light_curves = xo.utils.eval_in_model(model.light_curves, model.map_soln)\n",
    "\n",
    "plt.plot(model.x, model.y - mean, \"k\", label=\"data\")\n",
    "for n, l in enumerate(letters):\n",
    "    plt.plot(model.x, 1e3 * light_curves[:, n], label=\"planet {0}\".format(l), zorder=100-n)\n",
    "\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"flux [ppt]\")\n",
    "plt.title(\"initial fit\")\n",
    "plt.xlim(model.x.min(), model.x.max())\n",
    "plt.legend(fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    light_curves = xo.utils.eval_in_model(model.light_curves, model.map_soln)\n",
    "\n",
    "for n, letter in enumerate(letters):\n",
    "    plt.figure()\n",
    "\n",
    "    # Compute the GP prediction\n",
    "    mean_mod = model.map_soln[\"mean\"]\n",
    "\n",
    "    # Get the posterior median orbital parameters\n",
    "    p = model.map_soln[\"period\"][n]\n",
    "    t0 = model.map_soln[\"t0\"][n]\n",
    "\n",
    "    # Compute the median of posterior estimate of the contribution from\n",
    "    # the other planet. Then we can remove this from the data to plot\n",
    "    # just the planet we care about.\n",
    "    inds = np.arange(len(periods)) != n\n",
    "    others = 1e3*np.sum(light_curves[:, inds], axis=-1)\n",
    "\n",
    "    # Plot the folded data\n",
    "    x_fold = (model.x - t0 + 0.5*p) % p - 0.5*p\n",
    "    plt.plot(x_fold, model.y - mean_mod - others, \".k\", label=\"data\", zorder=-1000)\n",
    "\n",
    "    # Plot the folded model\n",
    "    inds = np.argsort(x_fold)\n",
    "    inds = inds[np.abs(x_fold)[inds] < 0.3]\n",
    "    pred = 1e3 * light_curves[inds, n]\n",
    "    plt.plot(x_fold[inds], pred, color=\"C1\", label=\"model\")\n",
    "\n",
    "    # Annotate the plot with the planet's period\n",
    "    txt = \"period = {0:.4f} d\".format(p)\n",
    "    plt.annotate(txt, (0, 0), xycoords=\"axes fraction\",\n",
    "                 xytext=(5, 5), textcoords=\"offset points\",\n",
    "                 ha=\"left\", va=\"bottom\", fontsize=12)\n",
    "\n",
    "    plt.legend(fontsize=10, loc=4)\n",
    "    plt.xlim(-0.5*p, 0.5*p)\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"de-trended flux\")\n",
    "    plt.title(\"TOI {0}{1}\".format(toi_num, letter));\n",
    "    plt.xlim(-0.3, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "sampler = xo.PyMC3Sampler(window=50, start=50, finish=500)\n",
    "with model:\n",
    "    burnin = sampler.tune(tune=3000, start=model.map_soln,\n",
    "                          step_kwargs=dict(target_accept=0.9),\n",
    "                          chains=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = sampler.sample(draws=1000, chains=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace, varnames=[\"mean\", \"u\", \"period\", \"t0\", \"r\", \"b\", \"logs2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    light_curves = np.empty((500, len(model.x), len(periods)))\n",
    "    func = xo.utils.get_theano_function_for_var(model.light_curves)\n",
    "    for i, sample in enumerate(xo.utils.get_samples_from_trace(\n",
    "            trace, size=len(light_curves))):\n",
    "        light_curves[i] = func(*xo.utils.get_args_for_theano_function(sample))\n",
    "\n",
    "for n, letter in enumerate(letters):\n",
    "    plt.figure()\n",
    "\n",
    "    # Compute the GP prediction\n",
    "    mean_mod = np.median(trace[\"mean\"][:, None])\n",
    "\n",
    "    # Get the posterior median orbital parameters\n",
    "    p = np.median(trace[\"period\"][:, n])\n",
    "    t0 = np.median(trace[\"t0\"][:, n])\n",
    "\n",
    "    # Compute the median of posterior estimate of the contribution from\n",
    "    # the other planet. Then we can remove this from the data to plot\n",
    "    # just the planet we care about.\n",
    "    inds = np.arange(len(periods)) != n\n",
    "    others = np.median(1e3*np.sum(light_curves[:, :, inds], axis=-1), axis=0)\n",
    "\n",
    "    # Plot the folded data\n",
    "    x_fold = (model.x - t0 + 0.5*p) % p - 0.5*p\n",
    "    plt.plot(x_fold, model.y - mean_mod - others, \".k\", label=\"data\", zorder=-1000)\n",
    "\n",
    "    # Plot the folded model\n",
    "    inds = np.argsort(x_fold)\n",
    "    inds = inds[np.abs(x_fold)[inds] < 0.3]\n",
    "    pred = 1e3 * light_curves[:, inds, n]\n",
    "    pred = np.percentile(pred, [16, 50, 84], axis=0)\n",
    "    plt.plot(x_fold[inds], pred[1], color=\"C1\", label=\"model\")\n",
    "    art = plt.fill_between(x_fold[inds], pred[0], pred[2], color=\"C1\", alpha=0.5,\n",
    "                           zorder=1000)\n",
    "    art.set_edgecolor(\"none\")\n",
    "\n",
    "    # Annotate the plot with the planet's period\n",
    "    txt = \"period = {0:.4f} +/- {1:.4f} d\".format(\n",
    "        np.mean(trace[\"period\"][:, n]), np.std(trace[\"period\"][:, n]))\n",
    "    plt.annotate(txt, (0, 0), xycoords=\"axes fraction\",\n",
    "                 xytext=(5, 5), textcoords=\"offset points\",\n",
    "                 ha=\"left\", va=\"bottom\", fontsize=12)\n",
    "\n",
    "    plt.legend(fontsize=10, loc=4)\n",
    "    plt.xlim(-0.5*p, 0.5*p)\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"de-trended flux\")\n",
    "    plt.title(\"TOI {0}{1}\".format(toi_num, letter));\n",
    "    plt.xlim(-0.3, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ror_samps = trace[\"r\"]\n",
    "r_star_samps = toi_r_star + toi_r_star_err * np.random.randn(len(ror_samps))\n",
    "r_pl = ror_samps * r_star_samps[:, None] * 109.07637070600963\n",
    "samples = np.concatenate((r_pl, trace[\"b\"]), axis=-1)\n",
    "\n",
    "labels = [\"$R_{{\\mathrm{{Pl}},{0}}}$ [$R_\\oplus$]\".format(i) for i in letters]\n",
    "labels += [\"impact param {0}\".format(i) for i in letters]\n",
    "\n",
    "corner.corner(samples, labels=labels,\n",
    "              show_titles=True, title_kwargs=dict(fontsize=10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"$P_{{{0}}}$ [days]\".format(i) for i in letters]\n",
    "labels += [\"$t0_{{{0}}}$ [TBJD]\".format(i) for i in letters]\n",
    "samples = np.concatenate((trace[\"period\"], trace[\"t0\"]), axis=-1)\n",
    "corner.corner(samples, labels=labels,\n",
    "              show_titles=True, title_fmt=\".5f\",\n",
    "              title_kwargs=dict(fontsize=10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trace[\"u\"]\n",
    "labels = [\"$u_1$\", \"$u_2$\"]\n",
    "corner.corner(samples, labels=labels,\n",
    "              show_titles=True, title_kwargs=dict(fontsize=10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
